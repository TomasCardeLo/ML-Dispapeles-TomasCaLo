{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pycaret.time_series import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion para descargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cluster(nits_clientes, fecha_final):\n",
    "    # Conexion al dwh\n",
    "    cnxn = pyodbc.connect(\n",
    "        driver='{SQL Server}',\n",
    "        server='192.168.100.58',\n",
    "        uid='bilectura',\n",
    "        pwd='D1sp@p3l3s')\n",
    "    cursor = cnxn.cursor()\n",
    "\n",
    "    df_SQL_nits = pd.DataFrame()\n",
    "\n",
    "    for nit in nits_clientes:\n",
    "        #Consulta SQL\n",
    "        # consulta_SQL = f\"SELECT DATEFROMPARTS(VTAANO, VTAMES, 1) AS 'Fecha', CONCAT(CONCAT(VTANIT, '-'), VTASUC) AS 'Nitcliente-sucursal', SUM(VTAVLRVTA) AS 'Ventas' FROM V_VTA_VTAHEC WHERE CONCAT(CONCAT(VTANIT, '-'), VTASUC) = '{nit}' AND VTAFCH BETWEEN '2021-01-01' AND '{fecha_final}' GROUP BY DATEFROMPARTS(VTAANO, VTAMES, 1), CONCAT(CONCAT(VTANIT, '-'), VTASUC)\"\n",
    "        consulta_SQL = f\"SELECT DATEFROMPARTS(VTAANO, VTAMES, 1) AS 'Fecha', CONCAT(CONCAT(VTANIT, '-'), VTASUC) AS 'Nitcliente-sucursal', SUM(VTAVLRVTA) AS 'Ventas' FROM V_VTA_VTAHEC WHERE CONCAT(CONCAT(VTANIT, '-'), VTASUC) = '{nit}' AND VTAFCH < '{fecha_final}' GROUP BY DATEFROMPARTS(VTAANO, VTAMES, 1), CONCAT(CONCAT(VTANIT, '-'), VTASUC)\"\n",
    "\n",
    "        #Carga de la data desde el dwh de Dispapeles y se guarda en df\n",
    "        cursor.execute(consulta_SQL)\n",
    "        rows = cursor.fetchall()\n",
    "        df_SQL_int = pd.DataFrame.from_records(rows, columns=[col[0] for col in cursor.description])\n",
    "        df_SQL_int[\"Ventas\"] = df_SQL_int[\"Ventas\"].astype(int)\n",
    "        df_SQL_int[\"Fecha\"] = pd.to_datetime(df_SQL_int[\"Fecha\"])\n",
    "\n",
    "        df_SQL_nits = pd.concat([df_SQL_nits, df_SQL_int], ignore_index= True)\n",
    "\n",
    "    df_SQL = df_SQL_nits.groupby(\"Fecha\").sum().reset_index()\n",
    "    df_SQL_nits = df_SQL_nits.groupby(\"Nitcliente-sucursal\").sum().reset_index()\n",
    "\n",
    "    return df_SQL, df_SQL_nits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_kwargs = {\n",
    "        # \"renderer\": \"notebook\",\n",
    "        \"renderer\": \"png\",\n",
    "        \"width\": 1000,\n",
    "        \"height\": 600,}\n",
    "\n",
    "def lineplot(bd):\n",
    "        x = bd[\"Fecha\"]\n",
    "        x_n = np.arange(0, len(bd))\n",
    "        y = bd[\"Ventas\"]   \n",
    "        coeficientes = np.polyfit(x_n, y, 1)\n",
    "        poli = np.poly1d(coeficientes)\n",
    "\n",
    "        trace1 = go.Scatter(x=x, y=y, mode='lines+markers', name='Ventas')\n",
    "        trace2 = go.Scatter(x=x, y=poli(x_n), mode='lines', name='Línea de Tendencia')\n",
    "\n",
    "        layout = go.Layout(\n",
    "                title='Ventas por mes',\n",
    "                xaxis=dict(title='Fecha'),\n",
    "                yaxis=dict(title='Ventas'),\n",
    "                legend=dict(x=1, y=1)\n",
    "        )\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(trace1)\n",
    "        fig.add_trace(trace2)\n",
    "        fig.update_layout(layout)\n",
    "        fig.show()\n",
    "\n",
    "def plot_estacionalidad(bd):\n",
    "        setup_ventas = setup(\n",
    "                bd, #df\n",
    "                target= \"Ventas\",\n",
    "                ignore_features= \"Suavizado\",\n",
    "                index= \"Fecha\",\n",
    "                session_id = 42, #id para mantener replicabilidad\n",
    "                transform_target= None, #transformador del target, \"box-cox\", \"log\", \"sqrt\", \"exp\", \"cos\"\n",
    "                coverage= 0.9, #intervalos\n",
    "                fh = 6,\n",
    "                use_gpu= True,\n",
    "                verbose= True,\n",
    "                hyperparameter_split= 'all', # all or train\n",
    "                )\n",
    "\n",
    "        setup_ventas.plot_model(plot= \"acf\")\n",
    "        setup_ventas.plot_model(plot= \"pacf\", data_kwargs= {\"nlags\": 12})\n",
    "\n",
    "def estadisticas_estacionalidad(bd):\n",
    "        setup_ventas = setup(\n",
    "                bd, #df\n",
    "                target= \"Ventas\",\n",
    "                ignore_features= \"Suavizado\",\n",
    "                index= \"Fecha\",\n",
    "                session_id = 42, #id para mantener replicabilidad\n",
    "                transform_target= None, #transformador del target, \"box-cox\", \"log\", \"sqrt\", \"exp\", \"cos\"\n",
    "                coverage= 0.9, #intervalos\n",
    "                fh = 6,\n",
    "                use_gpu= True,\n",
    "                verbose= True,\n",
    "                hyperparameter_split= 'all', # all or train\n",
    "                )\n",
    "        #Prueba Dickey-Fuller\n",
    "        df_adf = setup_ventas.check_stats(test='stationarity')\n",
    "        df_adf = df_adf[df_adf[\"Test Name\"] == \"ADF\"].iloc[:,-3:]\n",
    "        p_value = round(df_adf[\"Value\"][1], 4)\n",
    "        df_adf2 = df_adf.iloc[2:,:]\n",
    "        df_adf2 = df_adf2[[\"Property\", \"Value\"]]\n",
    "\n",
    "        print(\"Se realiza la prueba de Dickey-Fuller para analizar la estacionalidad de la serie de tiempo.\")\n",
    "        print(\"H0: la serie no es estacionaria\")\n",
    "        print(\"Con un alfa de 5% se determina:\")\n",
    "        #p_value\n",
    "        if p_value < 0.05:\n",
    "                print(f\"Se rechaza la H0 ya que el p_valor de {p_value} es menor al alfa\")\n",
    "        else:\n",
    "                print(f\"No se tiene suficiente evidencia para rechazar la H0, un p_valor de {p_value} es mayor al alfa\")\n",
    "        print(\"Por otro lado, los valores criticos de la prueba son los siguientes:\")\n",
    "        print(df_adf2)\n",
    "\n",
    "def EDA_cluster(bd, bd_nits):\n",
    "        #Variables\n",
    "        bd = bd.reset_index()\n",
    "        bd_nits = bd_nits\n",
    "        primer_fecha = datetime.utcfromtimestamp(bd.iloc[0, 1].timestamp())\n",
    "        ultima_fecha = datetime.utcfromtimestamp(bd.iloc[-1, 1].timestamp())\n",
    "        describe_bd = bd.describe().applymap(\"{:,.0f}\".format)\n",
    "        describe_bd_nits = bd_nits.describe().applymap(\"{:,.0f}\".format)\n",
    "\n",
    "        print(f\"Esta base de datos tiene ventas de {len(bd)} meses,\")\n",
    "        print(f\"empezando desde el {primer_fecha.strftime('%d-%m-%Y')}\")\n",
    "        print(f\"y terminando el {ultima_fecha.strftime('%d-%m-%Y')}\")\n",
    "        print(\"La composicion estadistica de la base de datos es la siguiente:\")\n",
    "        print(describe_bd[\"Ventas\"][1:])\n",
    "        print(\" \")\n",
    "\n",
    "        print(f\"Por otro lado, esta compuesto por ventas de {len(bd_nits)} clientes\")\n",
    "        print(\"Y asi se comporta estadisticamente asi:\")\n",
    "        print(describe_bd_nits[\"Ventas\"][1:])\n",
    "        print(\" \")\n",
    "        lineplot(bd)\n",
    "        plot_estacionalidad(bd)\n",
    "        estadisticas_estacionalidad(bd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion suavizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_suavizacion(bd, alpha, tipo_suavizacion):\n",
    "    # Visualizar la serie original y suavizada\n",
    "    x = bd[\"Fecha\"]\n",
    "    y1 = bd[\"Ventas\"]\n",
    "    y2 = bd[\"Suavizado\"]\n",
    "    trace1 = go.Scatter(x= x, y= y1, mode= \"lines+markers\", name= \"Ventas\")\n",
    "    trace2 = go.Scatter(x= x, y= y2, mode= \"lines+markers\", name= f\"Suavizado alfa {alpha}\")\n",
    "\n",
    "    layout = go.Layout(\n",
    "            title=f\"Ventas por mes, suavizado con {tipo_suavizacion} y alpha {alpha}\",\n",
    "            xaxis=dict(title=\"Fecha\"),\n",
    "            yaxis=dict(title=\"Ventas\"),\n",
    "            legend=dict(x=1, y=1)\n",
    "            )\n",
    "    # fig = go.Figure()\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    fig.add_trace(trace1, secondary_y= False)\n",
    "    fig.add_trace(trace2, secondary_y= True)\n",
    "    fig.update_yaxes(title_text=\"Ventas\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Suavizacion\", secondary_y=True)\n",
    "    fig.update_layout(layout)\n",
    "    fig.show()\n",
    "\n",
    "def suavizacion(bd, alpha= 0.2, tipo_suavizacion= \"exponencial simple\"):\n",
    "    # Aplicar suavización exponencial simple\n",
    "    if tipo_suavizacion == \"exponencial simple\":\n",
    "        bd[\"Suavizado\"] = bd[\"Ventas\"].ewm(alpha=alpha).mean()\n",
    "    elif tipo_suavizacion == \"logaritmica\":\n",
    "        bd[\"Suavizado\"] = np.log(bd[\"Ventas\"]).ewm(alpha=alpha).mean()\n",
    "    else:\n",
    "        bd[\"Suavizado\"] = np.sqrt(bd[\"Ventas\"]).ewm(alpha=alpha).mean()\n",
    "    \n",
    "    plot_suavizacion(bd, alpha, tipo_suavizacion)\n",
    "    \n",
    "    return bd\n",
    "\n",
    "def inversa_suavizacion(bd, tipo_suavizacion= \"exponencial simple\"):\n",
    "    if tipo_suavizacion == \"logaritmica\":\n",
    "        print(np.exp(bd))\n",
    "    elif tipo_suavizacion == \"raiz cuadrada\":\n",
    "        print(bd.apply(lambda x: x**2))\n",
    "    else:\n",
    "        print(bd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraccion, tranformacion y analisis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.read_csv(\"C:/Users/tcardenas/OneDrive/OneDrive - Grupo DISPAPELES/Documents/ML-Dispapeles-TomasCaLo/Clustering/Clustering 12-04-23.csv\",\n",
    "                            encoding= 'utf-8', decimal= \",\", sep= \";\")\n",
    "col_eliminar = [\"Escala R\", \"Escala M\", \"Escala F\", \"Distrito-Nombretipozona\", \"Cluster\"]\n",
    "df_clusters = df_clusters.drop(col_eliminar, axis= 1)\n",
    "\n",
    "#El mejor modelo es 10-Institucional-A\n",
    "filtro_distrito = 10\n",
    "filtro_tipozona = \"Institucional\"\n",
    "filtro_cluster = \"A\"\n",
    "\n",
    "df_clusters_f = df_clusters[\n",
    "                            (df_clusters[\"Codigo distrito\"] == filtro_distrito) &\n",
    "                            (df_clusters[\"Nombre tipo zona\"] == filtro_tipozona) &\n",
    "                            (df_clusters[\"Letra cluster\"] == filtro_cluster)\n",
    "                            ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA del cluster elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion del df a realizar EDA\n",
    "df_clusters_EDA = df_clusters.groupby([\"Codigo distrito\", \"Nombre tipo zona\", \"Letra cluster\"]).agg({\"Nit cliente-sucursal\": np.size}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables auxiliares\n",
    "lista_nits = df_clusters_f[\"Nit cliente-sucursal\"].tolist()\n",
    "fecha_final = '2023-03-31'\n",
    "fecha_final = datetime.strptime(fecha_final, '%Y-%m-%d').strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs para EDA y forecast\n",
    "ventas_cluster, ventas_nits = df_cluster(nits_clientes= lista_nits, fecha_final= fecha_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_cluster(ventas_cluster, ventas_nits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El tipo de suavizacion puede ser:\n",
    "    #Exponencial simple\n",
    "    #Logaritmica\n",
    "    #Raiz cuadrada\n",
    "ventas_cluster = suavizacion(ventas_cluster, alpha= 0.2, tipo_suavizacion= \"exponencial simple\")\n",
    "# ventas_cluster = suavizacion(ventas_cluster, alpha= 0.2, tipo_suavizacion= \"logaritmica\")\n",
    "# ventas_cluster = suavizacion(ventas_cluster, alpha= 0.2, tipo_suavizacion= \"raiz cuadrada\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuracion y prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_suavizado = setup(\n",
    "            ventas_cluster, #df\n",
    "            target= \"Suavizado\",\n",
    "            ignore_features= \"Ventas\",\n",
    "            index= \"Fecha\",\n",
    "            session_id = 42, #id para mantener replicabilidad\n",
    "            transform_target= None, #transformador del target, \"box-cox\", \"log\", \"sqrt\", \"exp\", \"cos\"\n",
    "            coverage= 0.9, #intervalos\n",
    "            fh = 6,\n",
    "            use_gpu= True,\n",
    "            verbose= True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_metric('RMSE')\n",
    "# remove_metric('RMSSE')\n",
    "# remove_metric('SMAPE')\n",
    "# remove_metric('MAE')\n",
    "top_models = compare_models(\n",
    "                        n_select= 3,\n",
    "                        sort= \"r2\"\n",
    "                        )\n",
    "metricas_completas = pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer el formato de visualización de números en notación decimal\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "metricas_completas.loc[metricas_completas[\"R2\"] > 0]\n",
    "# metricas_completas\n",
    "# metricas_completas[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(top_models, plot = 'forecast', data_kwargs = {'fh': 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "final_model = setup_suavizado.finalize_model(top_models[0])\n",
    "inversa_suavizacion(setup_suavizado.predict_model(final_model), tipo_suavizacion= \"exponencial simple\")\n",
    "setup_suavizado.plot_model(final_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6c6a9368ffd28e969f7d90a4d7c29e7466278b3cb1a367b914bbfe92c83c635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
