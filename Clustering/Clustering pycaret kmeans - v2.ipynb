{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cargue de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.clustering import *\n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conexion al DWH de Dispapeles y carga de bds adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clustering(consulta_SQL):\n",
    "    ## Conexion al DWH\n",
    "    cnxn = pyodbc.connect(\n",
    "        driver='{SQL Server}',\n",
    "        server='192.168.100.58',\n",
    "        uid='bilectura',\n",
    "        pwd='D1sp@p3l3s')\n",
    "    cursor = cnxn.cursor()\n",
    "    \n",
    "    #Cargue de la data desde el ERP de Dispapeles y se guarda en df\n",
    "    cursor.execute(consulta_SQL)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    df = pd.DataFrame.from_records(rows, columns=[col[0] for col in cursor.description])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta SQL para descargar la informacion a usar\n",
    "codigo_SQL = \"SELECT A.DSTCOD AS 'Codigo distrito', B.VNDZNA AS 'Codigo zona actual', CONCAT(CONCAT(A.VTANIT,'-'),A.VTASUC) AS 'Nit cliente-sucursal', A.VTAANO AS 'Ano', A.VTAMES AS 'Mes', (((2021 - MAX(A.VTAANO)) * 12 ) + (0 - MAX(A.VTAMES))) * -1 AS 'Recency', SUM(A.VTAVLRVTA) AS 'Monetary', COUNT( DISTINCT A.VTAMES) AS 'Frequency' FROM V_VTA_VTAHEC A LEFT JOIN\tDIM_CLIENTES B ON A.PRMCOD = B.PRMCOD AND A.DSTCOD = B.DSTCOD AND A.VTANIT = B.CLTNIT AND A.VTASUC = B.CLTSUC WHERE A.PRMCOD = 1 AND A.DSTCOD NOT IN (30,35) AND A.VTAZNA < 96 AND A.VTAFCH BETWEEN '2021-01-01' AND '2022-12-31' GROUP BY A.DSTCOD, B.VNDZNA, CONCAT(CONCAT(A.VTANIT,'-'),A.VTASUC), A.VTAANO, A.VTAMES HAVING SUM(A.VTAVLRVTA) > 0\"\n",
    "# Consulta adicional para establecer el tipo de zona\n",
    "maestra_zonas = pd.read_csv('C:/Users/tcardenas/OneDrive/OneDrive - Grupo DISPAPELES/Documents/Análisis clustering/Maestra_zonas.csv', delimiter= \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clustering(codigo_SQL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tranformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de tipo de la columna Monetary\n",
    "df[\"Monetary\"] = df[\"Monetary\"].astype(int)\n",
    "\n",
    "# Join con la maestra de zonas para determinar el tipo de zona\n",
    "df_2 = pd.merge(df, maestra_zonas, on= [\"Codigo distrito\", \"Codigo zona actual\"])\n",
    "\n",
    "# Filtro de la informacion para excluir zonas no relevantes\n",
    "list_filter = ['Artes graficas', 'TIG', 'V Horeca', 'Institucional', 'V SyE',\n",
    "                'V Industria', 'Mayorista']\n",
    "df = df_2[df_2[\"Nombre tipo zona\"].isin(list_filter)]\n",
    "\n",
    "# DF final agregada por tipo de zona\n",
    "df_3 = df.groupby([\"Codigo distrito\", \"Nombre tipo zona\", \"Nit cliente-sucursal\"]).agg({\"Recency\": np.max,\n",
    "                                                                            \"Monetary\": np.sum,\n",
    "                                                                            \"Frequency\": np.sum\n",
    "                                                                            })\n",
    "df_3 = df_3.reset_index(col_level= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se añade una key de Distrito-Nombretipozona para hacer mas facil la identificacion cuando se usa todo el pais\n",
    "# Se genera la calificacion de Recency basado en los valores máximos\n",
    "# Se divide por millón la columna Monetary para disminuir el rango de los valores\n",
    "df_3['Distrito-Nombretipozona'] = df_3['Codigo distrito'].astype(str) + '-' + df_3['Nombre tipo zona']\n",
    "df_3['Monetary'] = (df_3['Monetary'] / 1000).astype(int)\n",
    "df_3['Frequency'] = (df_3['Frequency']).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creacion, ajuste y descarga de los modelos de clustering por cada distrito-tipo de zona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dtos = df_3[\"Distrito-Nombretipozona\"].unique()\n",
    "numeric_features = [\"Recency\", \"Monetary\", \"Frequency\"]\n",
    "ignore_columns = [\"Codigo distrito\", \"Nombre tipo zona\", \"Nit cliente-sucursal\", \"Distrito-Nombretipozona\"]\n",
    "normalizar = [False, True]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dos modelos, norm= True y norm= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables iniciales\n",
    "bd_predicted = pd.DataFrame([])\n",
    "metrics = []\n",
    "\n",
    "# Fecha para guardar resultados\n",
    "fecha = '14-2-23'\n",
    "\n",
    "# Ciclo para realizar el modelo de clustering por cada tipo de zona del pais\n",
    "for norm in normalizar:\n",
    "    for n, dto in enumerate(list_dtos):\n",
    "        print(f\"Procesando modelo normalizado {norm} {n+1} de {len(list_dtos)}. {(n+1) / (len(list_dtos)):.1%}\")\n",
    "        \n",
    "        #BD filtrada\n",
    "        df_dto = df_3[df_3[\"Distrito-Nombretipozona\"] == dto]\n",
    "        \n",
    "        #Setup del modelo \n",
    "        s = setup(\n",
    "                    df_dto,\n",
    "                    normalize = norm,\n",
    "                    verbose= False,\n",
    "                    preprocess= False,\n",
    "                    silent= True,\n",
    "                    profile= False,\n",
    "                    ignore_features= ignore_columns,\n",
    "                    numeric_features= numeric_features\n",
    "                    )\n",
    "        \n",
    "        #Creacion y prediccion de modelo\n",
    "        model_kmeans = create_model(\n",
    "                                    'kmeans',\n",
    "                                    num_clusters= 5,\n",
    "                                    verbose= False,\n",
    "                                    )\n",
    "        pull()\n",
    "        df_pred_km = predict_model(\n",
    "                                    model_kmeans,\n",
    "                                    data = df_dto\n",
    "                                    )\n",
    "        \n",
    "        # Reasignacion de los nombres de los clusters\n",
    "        trans = df_pred_km.groupby(\n",
    "                                    [\"Cluster\"]).agg({\n",
    "                                                    \"Recency\": np.mean, \"Monetary\": np.mean, \"Frequency\": np.mean,\n",
    "                                                    }).sort_values(\n",
    "                                                                    by= [\"Monetary\", \"Frequency\", \"Recency\"],\n",
    "                                                                    ascending= False\n",
    "                                                                    ).reset_index()\n",
    "        trans[\"Letra cluster\"] = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "        trans = trans[[\"Cluster\", \"Letra cluster\"]]\n",
    "        \n",
    "        df_pred_km = pd.merge(df_pred_km, trans, on= [\"Cluster\"])\n",
    "        \n",
    "        # Descarga del modelo\n",
    "        bd_predicted = bd_predicted.append(df_pred_km)\n",
    "\n",
    "        #Append a la variable incial de metricas\n",
    "        metrics.append({\n",
    "                        \"Distrito-zona\": dto,\n",
    "                        \"Normalizado\": norm,\n",
    "                        \"Silhouette\": pull().Silhouette[0],\n",
    "                        \"Calinski-Harabasz\": pull()[\"Calinski-Harabasz\"][0],\n",
    "                        \"Davies-Bouldin\": pull()[\"Davies-Bouldin\"][0]\n",
    "                        })\n",
    "        # save_model(model_kmeans, f\"C:/Users/tcardenas/OneDrive/OneDrive - Grupo DISPAPELES/Documents/ML-Dispapeles-TomasCaLo/Clustering/Modelos {fecha}/Modelo {dto} {fecha}\")\n",
    "\n",
    "# Transformacion de la variable de metricas\n",
    "metrics = pd.DataFrame(metrics)\n",
    "metrics[\"Normalizado\"] = metrics[\"Normalizado\"].replace([True, False], [\"Si\",\"No\"])\n",
    "metrics[\"Tipo zona\"] = metrics[\"Distrito-zona\"].str[3:]\n",
    "\n",
    "print(\"Proceso completo 100%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Un solo modelo, norm= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_predicted = pd.DataFrame([])\n",
    "metrics = []\n",
    "fecha = '1-2-23'\n",
    "\n",
    "for n, dto in enumerate(list_dtos):\n",
    "    print(f\"Procesando modelo {n+1} de {len(list_dtos)}. {(n+1) / (len(list_dtos)):.1%}\")\n",
    "    \n",
    "    #BD filtrada\n",
    "    df_dto = df_3[df_3[\"Distrito-Nombretipozona\"] == dto]\n",
    "    \n",
    "    #Setup del modelo \n",
    "    s = setup(\n",
    "                df_dto,\n",
    "                normalize = False,\n",
    "                verbose= False,\n",
    "                preprocess= False,\n",
    "                silent= True,\n",
    "                profile= False,\n",
    "                ignore_features= ignore_columns,\n",
    "                numeric_features= numeric_features\n",
    "                )\n",
    "    \n",
    "    #Creacion y prediccion de modelo\n",
    "    model_kmeans = create_model(\n",
    "                                'kmeans',\n",
    "                                num_clusters= 5,\n",
    "                                verbose= False,\n",
    "                                )\n",
    "    pull()\n",
    "    df_pred_km = predict_model(\n",
    "                                model_kmeans,\n",
    "                                data = df_dto\n",
    "                                )\n",
    "    \n",
    "    # Reasignacion de los nombres de los clusters\n",
    "    trans = df_pred_km.groupby(\n",
    "                                [\"Cluster\"]).agg({\n",
    "                                                \"Recency\": np.mean, \"Monetary\": np.mean, \"Frequency\": np.mean,\n",
    "                                                }).sort_values(\n",
    "                                                                by= [\"Recency\", \"Frequency\", \"Monetary\"],\n",
    "                                                                ascending= False\n",
    "                                                                ).reset_index()\n",
    "    trans[\"Letra cluster\"] = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    trans = trans[[\"Cluster\", \"Letra cluster\"]]\n",
    "    \n",
    "    df_pred_km = pd.merge(df_pred_km, trans, on= [\"Cluster\"])\n",
    "    \n",
    "    # Descargue del modelo\n",
    "    bd_predicted = bd_predicted.append(df_pred_km)\n",
    "\n",
    "    #Append a una base general\n",
    "    metrics.append({\n",
    "                    \"Distrito-zona\": dto,\n",
    "                    \"Silhouette\": pull().Silhouette[0],\n",
    "                    \"Calinski-Harabasz\": pull()[\"Calinski-Harabasz\"][0],\n",
    "                    \"Davies-Bouldin\": pull()[\"Davies-Bouldin\"][0]\n",
    "                    })\n",
    "    # save_model(model_kmeans, f\"C:/Users/tcardenas/OneDrive/OneDrive - Grupo DISPAPELES/Documents/ML-Dispapeles-TomasCaLo/Clustering/Modelos {fecha}/Modelo {dto} {fecha}\")\n",
    "\n",
    "metrics = pd.DataFrame(metrics)\n",
    "metrics[\"Tipo zona\"] = metrics[\"Distrito-zona\"].str[3:]\n",
    "\n",
    "print(\"Proceso completo 100%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizacion y validacion clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots para validar si hay diferencia o no entre la data normalizada o no\n",
    "f, axarr = plt.subplots(2,3)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(25)\n",
    "\n",
    "metricas = [\"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"]\n",
    "\n",
    "for n, met in enumerate(metricas):\n",
    "    f.add_subplot(axarr[0,n])\n",
    "    plt.title(f\"Distribución {met}\").set_fontsize(15)\n",
    "    sns.set_theme(style=\"darkgrid\", palette= \"pastel\")\n",
    "    sns.boxplot(data= metrics, x= met, y= \"Tipo zona\", hue= 'Normalizado')\n",
    "\n",
    "    f.add_subplot(axarr[1,n])\n",
    "    sns.set_theme(style=\"darkgrid\", palette= \"pastel\")\n",
    "    sns.histplot(data= metrics, x= met, hue= 'Normalizado')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe de las metricas normalizadas\n",
    "metrics[metrics['Normalizado'] == \"Si\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe de las metricas NO normalizadas\n",
    "metrics[metrics['Normalizado'] == \"No\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga de bd predicha y metricas calculadas\n",
    "bd_predicted.to_csv(f\"C:/Users/tcardenas/OneDrive/OneDrive - Grupo DISPAPELES/Documents/ML-Dispapeles-TomasCaLo/Clustering/Clustering {fecha}.csv\",\n",
    "                        encoding= 'utf-8', index= False, decimal= \",\", sep= \";\")\n",
    "metrics.to_csv(f\"C:/Users/tcardenas/OneDrive/OneDrive - Grupo DISPAPELES/Documents/ML-Dispapeles-TomasCaLo/Clustering/Metricas {fecha}.csv\",\n",
    "                        encoding= 'utf-8', index= False, decimal= \",\",  sep= \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion de las \n",
    "fig = plt.figure(figsize=(7,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "m = ['o', 'v', 's', 'p', '*']\n",
    "col =  ['blueviolet', 'limegreen', 'indianred', 'royalblue', 'magenta']\n",
    "# leg = ['Cluster 0','Cluster 1','Cluster 2','Cluster 3', 'Cluster 4']\n",
    "leg = ['A', 'B', 'C', 'D', 'E']\n",
    "cluster = list(np.unique(df_pred_km['Letra cluster']))\n",
    "\n",
    "for c in range(5):\n",
    "    df_plot = df_pred_km[df_pred_km['Letra cluster'] == cluster[c]]\n",
    "    ax.scatter(df_plot['Monetary'],df_plot['Frequency'], df_plot['Recency'] , marker= m[c], c= col[c])\n",
    "    \n",
    "ax.legend(leg)\n",
    "ax.set_xlabel('Monetary')\n",
    "ax.set_ylabel('Recency')\n",
    "ax.set_zlabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_kmeans, plot = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_kmeans, plot = 'silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_kmeans, plot = 'distribution')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6c6a9368ffd28e969f7d90a4d7c29e7466278b3cb1a367b914bbfe92c83c635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
